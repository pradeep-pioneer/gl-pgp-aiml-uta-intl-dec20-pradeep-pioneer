{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PradeepSingh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['This is the first stage of qualification'\n",
    ", 'This is the second stage of qualification '\n",
    ", 'And the third one'\n",
    ", 'Is it the first stage again']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'again': 0, 'and': 1, 'first': 2, 'is': 3, 'it': 4, 'of': 5, 'one': 6, 'qualification': 7, 'second': 8, 'stage': 9, 'the': 10, 'third': 11, 'this': 12}\n",
      "\n",
      "\n",
      "['again', 'and', 'first', 'is', 'it', 'of', 'one', 'qualification', 'second', 'stage', 'the', 'third', 'this']\n",
      "[[0 0 1 1 0 1 0 1 0 1 1 0 1]\n",
      " [0 0 0 1 0 1 0 1 1 1 1 0 1]\n",
      " [0 1 0 0 0 0 1 0 0 0 1 1 0]\n",
      " [1 0 1 1 1 0 0 0 0 1 1 0 0]]\n",
      "(4, 13)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_vanilla = CountVectorizer()\n",
    "X_count_vectorizer_vanilla = vectorizer_vanilla.fit_transform(text)\n",
    "print(dict(sorted(vectorizer_vanilla.vocabulary_.items(), key=lambda item: item[1])))\n",
    "print('\\n')\n",
    "print(vectorizer_vanilla.get_feature_names())\n",
    "print(X_count_vectorizer_vanilla.toarray())\n",
    "print(X_count_vectorizer_vanilla.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and the', 'first stage', 'is it', 'is the', 'it the', 'of qualification', 'second stage', 'stage again', 'stage of', 'the first', 'the second', 'the third', 'third one', 'this is']\n",
      "[[0 1 0 1 0 1 0 0 1 1 0 0 0 1]\n",
      " [0 0 0 1 0 1 1 0 1 0 1 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 1 1 0 1 0 0 1 0 1 0 0 0 0]]\n",
      "(4, 14)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_word_bi_gram = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X_count_vectorizer_word_bi_gram = vectorizer_word_bi_gram.fit_transform(text)\n",
    "print(vectorizer_word_bi_gram.get_feature_names())\n",
    "print(X_count_vectorizer_word_bi_gram.toarray())\n",
    "print(X_count_vectorizer_word_bi_gram.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and the', 'and the third', 'first stage', 'first stage again', 'first stage of', 'is it', 'is it the', 'is the', 'is the first', 'is the second', 'it the', 'it the first', 'of qualification', 'second stage', 'second stage of', 'stage again', 'stage of', 'stage of qualification', 'the first', 'the first stage', 'the second', 'the second stage', 'the third', 'the third one', 'third one', 'this is', 'this is the']\n",
      "[[0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0 0 0 1 1]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      " [0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0]]\n",
      "(4, 27)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_word_tri_gram = CountVectorizer(analyzer='word', ngram_range=(2, 3))\n",
    "X_count_vectorizer_word_tri_gram = vectorizer_word_tri_gram.fit_transform(text)\n",
    "print(vectorizer_word_tri_gram.get_feature_names())\n",
    "print(X_count_vectorizer_word_tri_gram.toarray())\n",
    "print(X_count_vectorizer_word_tri_gram.toarray().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 12, 'is': 3, 'the': 10, 'first': 2, 'stage': 9, 'of': 5, 'qualification': 7, 'second': 8, 'and': 1, 'third': 11, 'one': 6, 'it': 4, 'again': 0}\n",
      "\n",
      "\n",
      "{'again': 1.916290731874155, 'and': 1.916290731874155, 'first': 1.5108256237659907, 'is': 1.2231435513142097, 'it': 1.916290731874155, 'of': 1.5108256237659907, 'one': 1.916290731874155, 'qualification': 1.5108256237659907, 'second': 1.916290731874155, 'stage': 1.2231435513142097, 'the': 1.0, 'third': 1.916290731874155, 'this': 1.5108256237659907}\n",
      "\n",
      "\n",
      "{'the': 1.0, 'is': 1.2231435513142097, 'stage': 1.2231435513142097, 'first': 1.5108256237659907, 'of': 1.5108256237659907, 'qualification': 1.5108256237659907, 'this': 1.5108256237659907, 'again': 1.916290731874155, 'and': 1.916290731874155, 'it': 1.916290731874155, 'one': 1.916290731874155, 'second': 1.916290731874155, 'third': 1.916290731874155}\n",
      "\n",
      "\n",
      "['again', 'and', 'first', 'is', 'it', 'of', 'one', 'qualification', 'second', 'stage', 'the', 'third', 'this']\n",
      "[[0.         0.         0.41706663 0.33765138 0.         0.41706663\n",
      "  0.         0.41706663 0.         0.33765138 0.27605213 0.\n",
      "  0.41706663]\n",
      " [0.         0.         0.         0.32107915 0.         0.39659663\n",
      "  0.         0.39659663 0.50303254 0.32107915 0.26250325 0.\n",
      "  0.39659663]\n",
      " [0.         0.55280532 0.         0.         0.         0.\n",
      "  0.55280532 0.         0.         0.         0.28847675 0.55280532\n",
      "  0.        ]\n",
      " [0.51926288 0.         0.40939282 0.33143877 0.51926288 0.\n",
      "  0.         0.         0.         0.33143877 0.27097291 0.\n",
      "  0.        ]]\n",
      "(4, 13)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_tf_idf_vanilla = TfidfVectorizer()\n",
    "X_tf_idf_vanilla = vectorizer_tf_idf_vanilla.fit_transform(text)\n",
    "print(vectorizer_tf_idf_vanilla.vocabulary_)\n",
    "print('\\n')\n",
    "idf = vectorizer_tf_idf_vanilla.idf_\n",
    "idf_values = dict(zip(vectorizer_tf_idf_vanilla.get_feature_names(), idf))\n",
    "print(idf_values)\n",
    "print('\\n')\n",
    "print(dict(sorted(idf_values.items(), key=lambda item: item[1])))\n",
    "print('\\n')\n",
    "print(vectorizer_tf_idf_vanilla.get_feature_names())\n",
    "print(X_tf_idf_vanilla.toarray())\n",
    "print(X_tf_idf_vanilla.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and the', 'first stage', 'is it', 'is the', 'it the', 'of qualification', 'second stage', 'stage again', 'stage of', 'the first', 'the second', 'the third', 'third one', 'this is']\n",
      "[[0.         0.40824829 0.         0.40824829 0.         0.40824829\n",
      "  0.         0.         0.40824829 0.40824829 0.         0.\n",
      "  0.         0.40824829]\n",
      " [0.         0.         0.         0.37222485 0.         0.37222485\n",
      "  0.47212003 0.         0.37222485 0.         0.47212003 0.\n",
      "  0.         0.37222485]\n",
      " [0.57735027 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.57735027\n",
      "  0.57735027 0.        ]\n",
      " [0.         0.38274272 0.48546061 0.         0.48546061 0.\n",
      "  0.         0.48546061 0.         0.38274272 0.         0.\n",
      "  0.         0.        ]]\n",
      "(4, 14)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_tf_idf_bi_gram = TfidfVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "X_tf_idf_bi_gram = vectorizer_tf_idf_bi_gram.fit_transform(text)\n",
    "print(vectorizer_tf_idf_bi_gram.get_feature_names())\n",
    "print(X_tf_idf_bi_gram.toarray())\n",
    "print(X_tf_idf_bi_gram.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and the', 'and the third', 'first stage', 'first stage again', 'first stage of', 'is it', 'is it the', 'is the', 'is the first', 'is the second', 'it the', 'it the first', 'of qualification', 'second stage', 'second stage of', 'stage again', 'stage of', 'stage of qualification', 'the first', 'the first stage', 'the second', 'the second stage', 'the third', 'the third one', 'third one', 'this is', 'this is the']\n",
      "[[0.         0.         0.28609357 0.         0.36287342 0.\n",
      "  0.         0.28609357 0.36287342 0.         0.         0.\n",
      "  0.28609357 0.         0.         0.         0.28609357 0.28609357\n",
      "  0.28609357 0.28609357 0.         0.         0.         0.\n",
      "  0.         0.28609357 0.28609357]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26684365 0.         0.33845733 0.         0.\n",
      "  0.26684365 0.33845733 0.33845733 0.         0.26684365 0.26684365\n",
      "  0.         0.         0.33845733 0.33845733 0.         0.\n",
      "  0.         0.26684365 0.26684365]\n",
      " [0.4472136  0.4472136  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4472136  0.4472136\n",
      "  0.4472136  0.         0.        ]\n",
      " [0.         0.         0.28113163 0.35657982 0.         0.35657982\n",
      "  0.35657982 0.         0.         0.         0.35657982 0.35657982\n",
      "  0.         0.         0.         0.35657982 0.         0.\n",
      "  0.28113163 0.28113163 0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n",
      "(4, 27)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_tf_idf_tri_gram = TfidfVectorizer(analyzer='word', ngram_range=(2,3))\n",
    "X_tf_idf_tri_gram = vectorizer_tf_idf_tri_gram.fit_transform(text)\n",
    "print(vectorizer_tf_idf_tri_gram.get_feature_names())\n",
    "print(X_tf_idf_tri_gram.toarray())\n",
    "print(X_tf_idf_tri_gram.toarray().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first stage', 'first stage qualification', 'second stage', 'second stage qualification', 'stage qualification', 'third one']\n",
      "[[1 1 0 0 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0]]\n",
      "(4, 6)\n"
     ]
    }
   ],
   "source": [
    "stop_words_english = set(stopwords.words(\"english\"))\n",
    "vectorizer_word_tri_gram = CountVectorizer(analyzer='word', ngram_range=(2, 3), stop_words=stop_words_english)\n",
    "X_count_vectorizer_word_tri_gram = vectorizer_word_tri_gram.fit_transform(text)\n",
    "print(vectorizer_word_tri_gram.get_feature_names())\n",
    "print(X_count_vectorizer_word_tri_gram.toarray())\n",
    "print(X_count_vectorizer_word_tri_gram.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first stage', 'first stage qualification', 'second stage', 'second stage qualification', 'stage qualification', 'third one']\n",
      "[[0.52640543 0.66767854 0.         0.         0.52640543 0.        ]\n",
      " [0.         0.         0.61761437 0.61761437 0.48693426 0.        ]\n",
      " [0.         0.         0.         0.         0.         1.        ]\n",
      " [1.         0.         0.         0.         0.         0.        ]]\n",
      "(4, 6)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_tf_idf_tri_gram = TfidfVectorizer(analyzer='word', ngram_range=(2,3), stop_words=stop_words_english)\n",
    "X_tf_idf_tri_gram = vectorizer_tf_idf_tri_gram.fit_transform(text)\n",
    "print(vectorizer_tf_idf_tri_gram.get_feature_names())\n",
    "print(X_tf_idf_tri_gram.toarray())\n",
    "print(X_tf_idf_tri_gram.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer_word_tri_gram: {'first stage': 0, 'stage qualification': 4, 'first stage qualification': 1, 'second stage': 2, 'second stage qualification': 3, 'third one': 5}\n",
      "vectorizer_tf_idf_tri_gram: {'first stage': 0, 'stage qualification': 4, 'first stage qualification': 1, 'second stage': 2, 'second stage qualification': 3, 'third one': 5}\n"
     ]
    }
   ],
   "source": [
    "print(f'vectorizer_word_tri_gram: {vectorizer_word_tri_gram.vocabulary_}')\n",
    "print(f'vectorizer_tf_idf_tri_gram: {vectorizer_tf_idf_tri_gram.vocabulary_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['again', 'and', 'is', 'it', 'of', 'one', 'qualification', 'stage', 'the', 'this']\n",
      "[[0 0 1 0 1 0 1 1 1 1]\n",
      " [0 0 1 0 1 0 1 1 1 1]\n",
      " [0 1 0 0 0 1 0 0 1 0]\n",
      " [1 0 1 1 0 0 0 1 1 0]]\n",
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_vanilla = CountVectorizer(stop_words= ['first','second','third'])\n",
    "X_count_vectorizer_vanilla = vectorizer_vanilla.fit_transform(text)\n",
    "print(vectorizer_vanilla.get_feature_names())\n",
    "print(X_count_vectorizer_vanilla.toarray())\n",
    "print(X_count_vectorizer_vanilla.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'is', 'of', 'stage', 'the']\n",
      "[[1 1 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [0 0 0 0 1]\n",
      " [1 1 0 1 1]]\n",
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_vanilla = CountVectorizer(max_features=5)\n",
    "X_count_vectorizer_vanilla = vectorizer_vanilla.fit_transform(text)\n",
    "print(vectorizer_vanilla.get_feature_names())\n",
    "print(X_count_vectorizer_vanilla.toarray())\n",
    "print(X_count_vectorizer_vanilla.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'stage', 'the']\n"
     ]
    }
   ],
   "source": [
    "vectorizer_tf_idf_vanilla = TfidfVectorizer(max_features=3)\n",
    "X_tf_idf_vanilla = vectorizer_tf_idf_vanilla.fit_transform(text)\n",
    "print(vectorizer_tf_idf_vanilla.get_feature_names())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GL-Python-3.7 (tensorflow-gpu)",
   "language": "python",
   "name": "gl-tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
